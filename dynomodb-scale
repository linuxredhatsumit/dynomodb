import argparse
import boto3
import time
from datetime import datetime
import logging
import json
import sys
import os
from botocore.exceptions import ClientError

class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_entry = {
            "timestamp": datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
            "level": record.levelname,
            "context": getattr(record, "context", "autoscaling"),
            "message": record.getMessage()
        }
        return json.dumps(log_entry)

logger = logging.getLogger()
handler = logging.StreamHandler(sys.stdout)
handler.setFormatter(JSONFormatter())
logger.addHandler(handler)
logger.setLevel(logging.INFO)

def get_table_description(dynamodb, table_name):
    try:
        return dynamodb.describe_table(TableName=table_name)['Table']
    except ClientError as e:
        logger.error(json.dumps({"context": "describe_table", "error": f"AWS Error: {e.response['Error']['Code']} - {e.response['Error']['Message']}"}))
        sys.exit(1)

def wait_for_table_active(dynamodb, table_name, target_billing_mode=None, max_wait=900):
    start_time = time.time()
    attempt = 0
    while time.time() - start_time < max_wait:
        desc = get_table_description(dynamodb, table_name)
        current_billing_mode = desc.get('BillingModeSummary', {}).get('BillingMode', 'PROVISIONED')
        elapsed_time = int(time.time() - start_time)
        if desc['TableStatus'] == 'ACTIVE' and (target_billing_mode is None or current_billing_mode == target_billing_mode):
            logger.info(json.dumps({
                "context": "wait_for_table_active",
                "message": f"Table {table_name} is ACTIVE with BillingMode {current_billing_mode} after {elapsed_time} seconds"
            }))
            return
        logger.info(json.dumps({
            "context": "wait_for_table_active",
            "message": f"Waiting for table {table_name} to become ACTIVE and BillingMode {target_billing_mode}... (current: {desc['TableStatus']}, {current_billing_mode}, elapsed time: {elapsed_time} seconds, attempt {attempt + 1})"
        }))
        time.sleep(10)
        attempt += 1
    logger.error(json.dumps({
        "context": "wait_for_table_active",
        "error": f"Timeout waiting for table {table_name} to become ACTIVE with BillingMode {target_billing_mode} after {max_wait} seconds"
    }))
    sys.exit(1)

def wait_for_no_scaling(autoscaling, resource_id, dimension):
    start_time = time.time()
    attempt = 0
    max_wait = 300
    while time.time() - start_time < max_wait:
        try:
            scalable_targets = autoscaling.describe_scalable_targets(
                ServiceNamespace='dynamodb',
                ResourceIds=[resource_id],
                ScalableDimension=dimension
            )['ScalableTargets']
            if not scalable_targets:
                elapsed_time = int(time.time() - start_time)
                logger.info(json.dumps({
                    "context": "wait_for_no_scaling",
                    "message": f"Autoscaling fully deregistered for {resource_id} with {dimension} after {elapsed_time} seconds"
                }))
                return
            logger.info(json.dumps({
                "context": "wait_for_no_scaling",
                "message": f"Waiting for autoscaling to deregister from {resource_id} with {dimension}... (elapsed time: {int(time.time() - start_time)} seconds, attempt {attempt + 1})"
            }))
            time.sleep(10)
            attempt += 1
        except ClientError as e:
            if e.response['Error']['Code'] == 'ValidationException' and 'No scalable targets' in e.response['Error']['Message']:
                elapsed_time = int(time.time() - start_time)
                logger.info(json.dumps({
                    "context": "wait_for_no_scaling",
                    "message": f"Autoscaling fully deregistered for {resource_id} with {dimension} after {elapsed_time} seconds"
                }))
                return
            logger.error(json.dumps({
                "context": "wait_for_no_scaling",
                "error": f"AWS Error: {e.response['Error']['Code']} - {e.response['Error']['Message']}"
            }))
            sys.exit(1)
    logger.error(json.dumps({
        "context": "wait_for_no_scaling",
        "error": f"Timeout waiting for autoscaling to deregister from {resource_id} with {dimension} after {max_wait} seconds"
    }))
    sys.exit(1)

def get_replica_regions(dynamodb, table_name):
    try:
        response = dynamodb.list_global_tables()
        global_tables = response.get('GlobalTables', [])
        for table in global_tables:
            if table['TableName'] == table_name:
                replicas = [replica['RegionName'] for replica in table.get('Replicas', [])]
                logger.info(json.dumps({
                    "context": "global_tables",
                    "message": f"Found replica regions for {table_name}: {replicas}"
                }))
                return replicas
        logger.info(json.dumps({
            "context": "global_tables",
            "message": f"Table {table_name} is not a Global Table or has no replicas."
        }))
        return []
    except ClientError as e:
        logger.error(json.dumps({"context": "global_tables", "error": f"AWS Error: {e.response['Error']['Code']} - {e.response['Error']['Message']}"}))
        sys.exit(1)

def load_gsi_config(table_name, check_gsi):
    if not check_gsi:
        logger.info("checkGSI is false. Skipping GSI config load.", extra={"context": "config.load"})
        return {}
    repo_root = os.environ.get("Build_SourcesDirectory", ".")
    repo_name = os.environ.get("REPOSITORY_NAME", "gsi-config-repo")
    folder_path = os.path.join(repo_root, repo_name, table_name)
    file_path = os.path.join(folder_path, "scaling.json")
    logger.info(f"Looking for config file at: {file_path}", extra={"context": "config.load"})
    if not os.path.exists(folder_path):
        logger.warning(json.dumps({
            "context": "config.load",
            "message": f"Table folder not found at: {folder_path}. Assuming no GSIs."
        }))
        return {}
    if not os.path.exists(file_path):
        logger.warning(json.dumps({
            "context": "config.load",
            "message": f"Scaling config file not found at: {file_path}. Assuming no GSIs."
        }))
        return {}
    try:
        with open(file_path, "r") as f:
            gsi_config = json.load(f)
        valid_projection_types = {"ALL", "KEYS_ONLY", "INCLUDE"}
        for index_name, conf in gsi_config.items():
            if "ProjectionType" in conf and conf["ProjectionType"] not in valid_projection_types:
                logger.error(json.dumps({
                    "context": "config.validate",
                    "error": f"Invalid ProjectionType for index {index_name}: {conf['ProjectionType']}. Must be one of {valid_projection_types}"
                }))
                sys.exit(1)
            if conf.get("ProjectionType") == "INCLUDE" and "NonKeyAttributes" not in conf:
                logger.error(json.dumps({
                    "context": "config.validate",
                    "error": f"NonKeyAttributes required for index {index_name} when ProjectionType is INCLUDE"
                }))
                sys.exit(1)
            if "NonKeyAttributes" in conf and not isinstance(conf["NonKeyAttributes"], list):
                logger.error(json.dumps({
                    "context": "config.validate",
                    "error": f"NonKeyAttributes for index {index_name} must be a list"
                }))
                sys.exit(1)
        logger.info(json.dumps({"context": "config.load", "message": f"Loaded GSI config: {gsi_config}"}))
        return gsi_config
    except json.JSONDecodeError as e:
        logger.error(json.dumps({"context": "config.load", "error": f"Invalid JSON format: {str(e)}"}))
        sys.exit(1)

def validate_gsi_config(desc, gsi_config, check_gsi):
    if not check_gsi or not gsi_config:
        logger.info("No GSI config to validate (checkGSI=false or no config found).", extra={"context": "config.validate"})
        return
    actual_indexes = set(gsi['IndexName'] for gsi in desc.get("GlobalSecondaryIndexes", []))
    config_indexes = set(gsi_config.keys())
    if actual_indexes != config_indexes:
        logger.error(json.dumps({
            "context": "config.validate",
            "error": "Mismatch between actual GSIs and scaling.json",
            "actual_indexes": list(actual_indexes),
            "config_indexes": list(config_indexes)
        }))
        sys.exit(1)

def deregister_scaling(autoscaling, table_name, dimension):
    try:
        autoscaling.deregister_scalable_target(
            ServiceNamespace="dynamodb",
            ResourceId=f"table/{table_name}",
            ScalableDimension=dimension
        )
        wait_for_no_scaling(autoscaling, f"table/{table_name}", dimension)
        logger.info(json.dumps({
            "context": f"autoscaling.deregister.{dimension}",
            "message": f"Deregistered scalable target for table/{table_name}"
        }))
    except ClientError as e:
        if e.response['Error']['Code'] != 'ObjectNotFoundException':
            logger.warning(json.dumps({
                "context": f"autoscaling.deregister.{dimension}",
                "warning": f"Failed to deregister: {e.response['Error']['Code']} - {e.response['Error']['Message']}"
            }))

def deregister_gsi_scaling(autoscaling, table_name, index_name):
    try:
        autoscaling.deregister_scalable_target(
            ServiceNamespace="dynamodb",
            ResourceId=f"table/{table_name}/index/{index_name}",
            ScalableDimension="dynamodb:index:ReadCapacityUnits"
        )
        wait_for_no_scaling(autoscaling, f"table/{table_name}/index/{index_name}", "dynamodb:index:ReadCapacityUnits")
        logger.info(json.dumps({
            "context": "autoscaling.deregister.gsi",
            "message": f"Deregistered scalable target for index {index_name} (ReadCapacityUnits)"
        }))
    except ClientError as e:
        if e.response['Error']['Code'] != 'ObjectNotFoundException':
            logger.warning(json.dumps({
                "context": "autoscaling.deregister.gsi",
                "warning": f"Failed to deregister read capacity for {index_name}: {e.response['Error']['Code']} - {e.response['Error']['Message']}"
            }))
    try:
        autoscaling.deregister_scalable_target(
            ServiceNamespace="dynamodb",
            ResourceId=f"table/{table_name}/index/{index_name}",
            ScalableDimension="dynamodb:index:WriteCapacityUnits"
        )
        wait_for_no_scaling(autoscaling, f"table/{table_name}/index/{index_name}", "dynamodb:index:WriteCapacityUnits")
        logger.info(json.dumps({
            "context": "autoscaling.deregister.gsi",
            "message": f"Deregistered scalable target for index {index_name} (WriteCapacityUnits)"
        }))
    except ClientError as e:
        if e.response['Error']['Code'] != 'ObjectNotFoundException':
            logger.warning(json.dumps({
                "context": "autoscaling.deregister.gsi",
                "warning": f"Failed to deregister write capacity for {index_name}: {e.response['Error']['Code']} - {e.response['Error']['Message']}"
            }))

def switch_to_pay_per_request(dynamodb, table_name, gsi_config):
    try:
        # Initial switch to PAY_PER_REQUEST for table
        dynamodb.update_table(
            TableName=table_name,
            BillingMode='PAY_PER_REQUEST'
        )
        wait_for_table_active(dynamodb, table_name, target_billing_mode="PAY_PER_REQUEST")
        logger.info(json.dumps({
            "context": "billing_mode",
            "message": f"Successfully switched table {table_name} to PAY_PER_REQUEST mode"
        }))

        # Update GSIs to PAY_PER_REQUEST if present
        if gsi_config:
            table_desc = get_table_description(dynamodb, table_name)
            existing_gsis = {gsi["IndexName"]: gsi for gsi in table_desc.get("GlobalSecondaryIndexes", [])}
            for index_name in gsi_config.keys():
                if index_name in existing_gsis:
                    dynamodb.update_table(
                        TableName=table_name,
                        GlobalSecondaryIndexUpdates=[{
                            "Update": {
                                "IndexName": index_name,
                                "BillingMode": "PAY_PER_REQUEST"
                            }
                        }]
                    )
                    wait_for_table_active(dynamodb, table_name, target_billing_mode="PAY_PER_REQUEST")
                    logger.info(json.dumps({
                        "context": "billing_mode",
                        "message": f"Switched GSI {index_name} to PAY_PER_REQUEST mode"
                    }))
        return True
    except ClientError as e:
        logger.error(json.dumps({
            "context": "billing_mode",
            "error": f"AWS Error: {e.response['Error']['Code']} - {e.response['Error']['Message']}"
        }))
        return False

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--tableName", required=True)
    parser.add_argument("--region", required=True)
    parser.add_argument("--readMode", choices=["ondemand", "provisioned"], required=True)
    parser.add_argument("--writeMode", choices=["ondemand", "provisioned"], required=True)
    parser.add_argument("--minRead", type=int)
    parser.add_argument("--maxRead", type=int)
    parser.add_argument("--targetRead", type=int)
    parser.add_argument("--minWrite", type=int)
    parser.add_argument("--maxWrite", type=int)
    parser.add_argument("--targetWrite", type=int)
    parser.add_argument("--maxReadUnits", type=int, help="Maximum read request units for PAY_PER_REQUEST mode")
    parser.add_argument("--maxWriteUnits", type=int, help="Maximum write request units for PAY_PER_REQUEST mode")
    parser.add_argument("--checkGSI", type=lambda x: x.lower() == 'true', default=True)
    parser.add_argument("--dry-run", action="store_true")
    args = parser.parse_args()
    if args.readMode == "provisioned":
        if args.minRead is None or args.minRead < 1:
            logger.error(json.dumps({
                "context": "args.validation",
                "error": f"minRead must be >= 1 for PROVISIONED mode, got {args.minRead}"
            }))
            sys.exit(1)
        if args.maxRead is None or args.maxRead < args.minRead:
            logger.error(json.dumps({
                "context": "args.validation",
                "error": f"maxRead must be >= minRead, got maxRead={args.maxRead}, minRead={args.minRead}"
            }))
            sys.exit(1)
        if args.targetRead is None or args.targetRead <= 0 or args.targetRead > 100:
            logger.error(json.dumps({
                "context": "args.validation",
                "error": f"targetRead must be between 1 and 100, got {args.targetRead}"
            }))
            sys.exit(1)
    if args.writeMode == "provisioned":
        if args.minWrite is None or args.minWrite < 1:
            logger.error(json.dumps({
                "context": "args.validation",
                "error": f"minWrite must be >= 1 for PROVISIONED mode, got {args.minWrite}"
            }))
            sys.exit(1)
        if args.maxWrite is None or args.maxWrite < args.minWrite:
            logger.error(json.dumps({
                "context": "args.validation",
                "error": f"maxWrite must be >= minWrite, got maxWrite={args.maxWrite}, minWrite={args.minWrite}"
            }))
            sys.exit(1)
        if args.targetWrite is None or args.targetWrite <= 0 or args.targetWrite > 100:
            logger.error(json.dumps({
                "context": "args.validation",
                "error": f"targetWrite must be between 1 and 100, got {args.targetWrite}"
            }))
            sys.exit(1)
    logger.info(json.dumps({
        "context": "args",
        "message": f"Received arguments: tableName={args.tableName}, region={args.region}, readMode={args.readMode}, writeMode={args.writeMode}, minRead={args.minRead}, maxRead={args.maxRead}, targetRead={args.targetRead}, minWrite={args.minWrite}, maxWrite={args.maxWrite}, targetWrite={args.targetWrite}, maxReadUnits={args.maxReadUnits}, maxWriteUnits={args.maxWriteUnits}, checkGSI={args.checkGSI}, dry-run={args.dry_run}"
    }))
    dynamodb = boto3.client("dynamodb", region_name=args.region)
    autoscaling = boto3.client("application-autoscaling", region_name=args.region)
    logger.info("Found credentials from IAM Role: vpn-access", extra={"context": "autoscaling"})
    desc = get_table_description(dynamodb, args.tableName)
    current_mode = desc.get('BillingModeSummary', {}).get('BillingMode', 'PROVISIONED')
    gsi_config = load_gsi_config(args.tableName, args.checkGSI)
    validate_gsi_config(desc, gsi_config, args.checkGSI)
    if args.dry_run:
        logger.info(json.dumps({
            "context": "dry_run",
            "message": "Dry run mode - no changes applied",
            "tableName": args.tableName,
            "targetBilling": args.readMode,
            "checkGSI": args.checkGSI,
            "maxReadUnits": args.maxReadUnits,
            "maxWriteUnits": args.maxWriteUnits
        }))
        sys.exit(0)
    replica_regions = get_replica_regions(dynamodb, args.tableName)
    logger.info(json.dumps({
        "context": "global_tables",
        "message": f"Found replica regions: {replica_regions}"
    }))
    if args.readMode == "provisioned" or args.writeMode == "provisioned":
        if current_mode == "PAY_PER_REQUEST":
            deregister_scaling(autoscaling, args.tableName, "dynamodb:table:ReadCapacityUnits")
            deregister_scaling(autoscaling, args.tableName, "dynamodb:table:WriteCapacityUnits")
        update_kwargs = {
            'TableName': args.tableName,
            'BillingMode': 'PROVISIONED',
            'ProvisionedThroughput': {
                'ReadCapacityUnits': args.minRead or 5,
                'WriteCapacityUnits': args.minWrite or 5
            }
        }
        if gsi_config:
            gsi_updates = []
            for gsi_name in gsi_config.keys():
                gsi_updates.append({
                    'Update': {
                        'IndexName': gsi_name,
                        'ProvisionedThroughput': {
                            'ReadCapacityUnits': gsi_config[gsi_name].get("ReadCapacityUnits", 5),
                            'WriteCapacityUnits': gsi_config[gsi_name].get("WriteCapacityUnits", 5)
                        }
                    }
                })
            update_kwargs["GlobalSecondaryIndexUpdates"] = gsi_updates
            logger.info(json.dumps({
                "context": "update_billing_mode",
                "message": f"Including GSI updates for PROVISIONED mode: {gsi_updates}"
            }))
        dynamodb.update_table(**update_kwargs)
        wait_for_table_active(dynamodb, args.tableName, target_billing_mode="PROVISIONED")
        if args.readMode == "provisioned":
            register_scaling(autoscaling, args.tableName, "dynamodb:table:ReadCapacityUnits",
                            args.minRead, args.maxRead, args.targetRead)
        if args.writeMode == "provisioned":
            register_scaling(autoscaling, args.tableName, "dynamodb:table:WriteCapacityUnits",
                            args.minWrite, args.maxWrite, args.targetWrite)
        if args.checkGSI and gsi_config:
            for index_name, conf in gsi_config.items():
                logger.info(json.dumps({
                    "context": "autoscaling.config",
                    "message": f"Applying autoscaling for index: {index_name}"
                }))
                if "MinReadCapacityUnits" in conf:
                    register_scaling(
                        autoscaling,
                        args.tableName,
                        "dynamodb:index:ReadCapacityUnits",
                        conf["MinReadCapacityUnits"],
                        conf["MaxReadCapacityUnits"],
                        conf["TargetReadUtilization"],
                        index_name=index_name
                    )
                if "MinWriteCapacityUnits" in conf:
                    register_scaling(
                        autoscaling,
                        args.tableName,
                        "dynamodb:index:WriteCapacityUnits",
                        conf["MinWriteCapacityUnits"],
                        conf["MaxWriteCapacityUnits"],
                        conf["TargetWriteUtilization"],
                        index_name=index_name
                    )
        logger.info(json.dumps({
            "context": "pipeline.verification",
            "message": f"Pipeline completed successfully for table {args.tableName} in region {args.region}"
        }))
        sys.exit(0)
    else:
        if current_mode == "PROVISIONED":
            # Deregister all scaling
            deregister_scaling(autoscaling, args.tableName, "dynamodb:table:ReadCapacityUnits")
            deregister_scaling(autoscaling, args.tableName, "dynamodb:table:WriteCapacityUnits")
            if gsi_config:
                for index_name in gsi_config.keys():
                    deregister_gsi_scaling(autoscaling, args.tableName, index_name)
            # Switch to PAY_PER_REQUEST
            if not switch_to_pay_per_request(dynamodb, args.tableName, gsi_config):
                logger.error(json.dumps({
                    "context": "billing_mode",
                    "error": f"Failed to switch {args.tableName} to PAY_PER_REQUEST mode"
                }))
                sys.exit(1)
        # Apply OnDemandThroughput if specified
        if args.maxReadUnits is not None or args.maxWriteUnits is not None:
            update_kwargs = {
                'TableName': args.tableName,
                'BillingMode': 'PAY_PER_REQUEST',
                'OnDemandThroughput': {}
            }
            if args.maxReadUnits is not None:
                logger.info(json.dumps({
                    "context": "update_billing_mode",
                    "message": f"Setting maximum read request units to {args.maxReadUnits}"
                }))
                update_kwargs['OnDemandThroughput']['MaxReadRequestUnits'] = args.maxReadUnits
            if args.maxWriteUnits is not None:
                logger.info(json.dumps({
                    "context": "update_billing_mode",
                    "message": f"Setting maximum write request units to {args.maxWriteUnits}"
                }))
                update_kwargs['OnDemandThroughput']['MaxWriteRequestUnits'] = args.maxWriteUnits
            dynamodb.update_table(**update_kwargs)
            wait_for_table_active(dynamodb, args.tableName, target_billing_mode="PAY_PER_REQUEST")
        logger.info(json.dumps({
            "context": "pipeline.verification",
            "message": f"Pipeline completed successfully for table {args.tableName} in region {args.region}"
        }))
        sys.exit(0)
    all_regions = [args.region] + replica_regions
    for region in all_regions:
        region_dynamodb = boto3.client("dynamodb", region_name=region)
        final_desc = get_table_description(region_dynamodb, args.tableName)
        logger.info(json.dumps({
            "context": "table.verification",
            "message": f"Final table configuration in region {region}",
            "TableName": args.tableName,
            "BillingMode": final_desc.get("BillingModeSummary", {}).get("BillingMode", "PROVISIONED"),
            "ReadCapacityUnits": final_desc.get("ProvisionedThroughput", {}).get("ReadCapacityUnits", 0),
            "WriteCapacityUnits": final_desc.get("ProvisionedThroughput", {}).get("WriteCapacityUnits", 0),
            "MaxReadRequestUnits": final_desc.get("OnDemandThroughput", {}).get("MaxReadRequestUnits", "Not set"),
            "MaxWriteRequestUnits": final_desc.get("OnDemandThroughput", {}).get("MaxWriteRequestUnits", "Not set")
        }))

def register_scaling(autoscaling, table_name, dimension, min_capacity, max_capacity, target_utilization, index_name=None):
    if dimension.startswith("dynamodb:table:"):
        resource_id = f"table/{table_name}"
    elif index_name:
        resource_id = f"table/{table_name}/index/{index_name}"
    else:
        logger.error(json.dumps({
            "context": f"autoscaling.register.{dimension}",
            "error": "Index name is required for GSI autoscaling"
        }))
        sys.exit(1)
    policy_name = f"{resource_id.replace('/', '-')}-{dimension.split(':')[-1]}-policy"
    try:
        if min_capacity < 1:
            logger.error(json.dumps({
                "context": f"autoscaling.register.{dimension}",
                "error": f"MinCapacity must be >= 1, got {min_capacity}"
            }))
            sys.exit(1)
        if max_capacity < min_capacity:
            logger.error(json.dumps({
                "context": f"autoscaling.register.{dimension}",
                "error": f"MaxCapacity must be >= MinCapacity, got max={max_capacity}, min={min_capacity}"
            }))
            sys.exit(1)
        if target_utilization <= 0 or target_utilization > 100:
            logger.error(json.dumps({
                "context": f"autoscaling.register.{dimension}",
                "error": f"TargetUtilization must be between 1 and 100, got {target_utilization}"
            }))
            sys.exit(1)
        logger.info(json.dumps({
            "context": f"autoscaling.register.{dimension}",
            "message": f"Parameters for scalable target: min={min_capacity}, max={max_capacity}, target={target_utilization}"
        }))
        try:
            autoscaling.deregister_scalable_target(
                ServiceNamespace="dynamodb",
                ResourceId=resource_id,
                ScalableDimension=dimension
            )
            logger.info(json.dumps({
                "context": f"autoscaling.cleanup.{dimension}",
                "message": f"Deregistered existing scalable target for {resource_id}"
            }))
        except ClientError as e:
            if e.response['Error']['Code'] != 'ObjectNotFoundException':
                logger.warning(json.dumps({
                    "context": f"autoscaling.cleanup.{dimension}",
                    "warning": f"Failed to deregister existing scalable target: {e.response['Error']['Code']} - {e.response['Error']['Message']}"
                }))
        scalable_targets = autoscaling.describe_scalable_targets(
            ServiceNamespace='dynamodb',
            ResourceIds=[resource_id],
            ScalableDimension=dimension
        )['ScalableTargets']
        existing_policies = autoscaling.describe_scaling_policies(
            ServiceNamespace='dynamodb',
            ResourceId=resource_id,
            ScalableDimension=dimension
        )['ScalingPolicies']
        policy_matches = False
        if scalable_targets and existing_policies:
            target = scalable_targets[0]
            policy = existing_policies[0]
            current_min = target.get('MinCapacity', 0)
            current_max = target.get('MaxCapacity', 0)
            current_target_value = policy.get('TargetTrackingScalingPolicyConfiguration', {}).get('TargetValue', 0)
            if (current_min == min_capacity and
                current_max == max_capacity and
                current_target_value == target_utilization and
                policy.get('PolicyType') == 'TargetTrackingScaling'):
                policy_matches = True
                logger.info(json.dumps({
                    "context": f"autoscaling.register.{dimension}",
                    "message": f"No updates needed for autoscaling policy: {policy_name}, settings already match (min={min_capacity}, max={max_capacity}, target={target_utilization})"
                }))
                return
        autoscaling.register_scalable_target(
            ServiceNamespace="dynamodb",
            ResourceId=resource_id,
            ScalableDimension=dimension,
            MinCapacity=min_capacity,
            MaxCapacity=max_capacity
        )
        for pol in existing_policies:
            logger.info(json.dumps({
                "context": f"autoscaling.cleanup.{dimension}",
                "message": f"Deleting existing policy: {pol['PolicyName']}"
            }))
            autoscaling.delete_scaling_policy(
                PolicyName=pol['PolicyName'],
                ServiceNamespace='dynamodb',
                ResourceId=resource_id,
                ScalableDimension=dimension
            )
        autoscaling.put_scaling_policy(
            PolicyName=policy_name,
            ServiceNamespace="dynamodb",
            ResourceId=resource_id,
            ScalableDimension=dimension,
            PolicyType='TargetTrackingScaling',
            TargetTrackingScalingPolicyConfiguration={
                'TargetValue': float(target_utilization),
                'PredefinedMetricSpecification': {
                    'PredefinedMetricType': 'DynamoDBReadCapacityUtilization'
                    if "Read" in dimension else 'DynamoDBWriteCapacityUtilization'
                },
                'ScaleInCooldown': 60,
                'ScaleOutCooldown': 60
            }
        )
        logger.info(json.dumps({
            "context": f"autoscaling.register.{dimension}",
            "message": "Scaling policy registered successfully"
        }))
        scalable_targets = autoscaling.describe_scalable_targets(
            ServiceNamespace='dynamodb',
            ResourceIds=[resource_id],
            ScalableDimension=dimension
        )['ScalableTargets']
        if scalable_targets:
            target = scalable_targets[0]
            logger.info(json.dumps({
                "context": f"autoscaling.verification.{dimension}",
                "message": f"Verified autoscaling settings for {resource_id}",
                "MinCapacity": target.get('MinCapacity'),
                "MaxCapacity": target.get('MaxCapacity')
            }))
        policies = autoscaling.describe_scaling_policies(
            ServiceNamespace='dynamodb',
            ResourceId=resource_id,
            ScalableDimension=dimension
        )['ScalingPolicies']
        if policies:
            policy = policies[0]
            logger.info(json.dumps({
                "context": f"autoscaling.verification.{dimension}",
                "message": f"Verified scaling policy for {resource_id}",
                "TargetValue": policy.get('TargetTrackingScalingPolicyConfiguration', {}).get('TargetValue')
            }))
    except ClientError as e:
        logger.error(json.dumps({
            "context": f"autoscaling.register.{dimension}",
            "error": f"AWS Error: {e.response['Error']['Code']} - {e.response['Error']['Message']}"
        }))
        sys.exit(1)

if __name__ == "__main__":
    main()
