import subprocess
from datetime import datetime

def get_hpa_data(context):
    try:
        result = subprocess.check_output(
            f"kubectl --context={context} get hpa -A -o jsonpath='{{range .items[*]}}{{.metadata.namespace}},{{.metadata.name}},{{.spec.minReplicas}},{{.spec.maxReplicas}}{{\"\\n\"}}{{end}}'",
            shell=True
        ).decode("utf-8")
        return result.strip().split("\n")
    except subprocess.CalledProcessError:
        print(f"Failed to get HPA data for context: {context}")
        return []

def calculate_scaled_value(original, percentage):
    return max(1, int(original * (percentage / 100.0)))

def process_cluster(source_context, target_context, percentage):
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"{target_context}_hpa_{timestamp}.txt"

    source_data = get_hpa_data(source_context)
    target_data = get_hpa_data(target_context)

    target_dict = {}
    for line in target_data:
        parts = line.split(",")
        if len(parts) == 4:
            target_dict[(parts[0], parts[1])] = (int(parts[2]), int(parts[3]))

    with open(output_file, "w") as f:
        for line in source_data:
            parts = line.split(",")
            if len(parts) != 4:
                continue

            ns, name, smin, smax = parts[0], parts[1], int(parts[2]), int(parts[3])

            new_min = calculate_scaled_value(smin, percentage)
            new_max = calculate_scaled_value(smax, percentage)

            f.write(f"{ns},{name},Min:{new_min},Max:{new_max}\n")

    print(f"Output saved: {output_file}")
    return output_file


if __name__ == "__main__":
    prod_context = "kprod"
    blue_context = "kblue"
    green_context = "kgreen"

    percentage = float(input("Enter percentage to scale (ex: 70 for 70%): "))

    print("\nProcessing for BLUE cluster...")
    process_cluster(prod_context, blue_context, percentage)

    print("\nProcessing for GREEN cluster...")
    process_cluster(prod_context, green_context, percentage)

    print("\nðŸŽ¯ Done! No changes made to Kubernetes. Only files generated.")